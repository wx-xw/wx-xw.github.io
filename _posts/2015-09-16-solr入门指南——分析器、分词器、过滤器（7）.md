---
layout: post
category: solr
tags: [solr,搜索]

---

## 过滤器（五）


### Synonym Filter

同义词过滤器，会给分词后的每个词进行同义词匹配

**工厂类**：solr.SynonymFilterFactory

**参数**

- synonyms：（必须）同义词表路径。
	- 逗号分隔词，所有的词都是同等地位，都是同义词
	- “=>”符号分隔词。替换词，左边的词被右边的替换掉
- ignoreCase：（选填，布尔，默认假）如果真，则大小写敏感
- expand：（选填，布尔，默认真）如果真，则将多个替换词都列出来，否则直列出第一个词
- format：（选填，默认solr）同义词书写的格式。可以自定义类来解析
- tokenizerFactory：（选填，默认WhitespaceTokenizerFactory）和analyzer参数，可以只有一个
- analyzer：（选填，默认WhitespaceTokenizerFactory）和tokenizerFactory参数，可以只有一个

> couch,sofa,divan
> teh => the
> huge,ginormous,humungous => large
> small => tiny,teeny,weeny

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SynonymFilterFactory" synonyms="mysynonyms.txt"/>
</analyzer>
```

**输入**："teh small couch"

**分词后**："teh"(1), "small"(2), "couch"(3)

**输出**："the"(1), "tiny"(2), "teeny"(2), "weeny"(2), "couch"(3), "sofa"(3), "divan"(3)

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SynonymFilterFactory" synonyms="mysynonyms.txt"/>
</analyzer>
```

**输入**："teh ginormous, humungous sofa"

**分词后**："teh"(1), "ginormous"(2), "humungous"(3), "sofa"(4)

**输出**："the"(1), "large"(2), "large"(3), "couch"(4), "sofa"(4), "divan"(4)

### Token Offset Payload Filter

将分词结果加上偏移量，作为词的payload的值

**工厂类**：solr.TokenOffsetPayloadTokenFilterFactory

**参数**：无

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.TokenOffsetPayloadTokenFilterFactory"/>
</analyzer>
```

**输入**："bing bang boom"

**分词后**："bing", "bang", "boom"

**输出**："bing"[0,4], "bang"[5,9], "boom"[10,14]

### Trim Filter

删除词的前后空格。

**工厂类**：solr.TrimFilterFactory

**参数**

- updateOffsets：5.0以后版本，此参数失效。4.3以前版本默认为true，回修改trim后的词的偏移量

```xml
<analyzer>
  <tokenizer class="solr.PatternTokenizerFactory" pattern=","/>
  <filter class="solr.TrimFilterFactory"/>
</analyzer>
```

**输入**："one, two , three ,four "

**分词后**："one", " two ", " three ", "four "

**输出**："one", "two", "three", "four"

### Type As Payload Filter

这个过滤器会加入词类型

**工厂类**：solr.TypeAsPayloadTokenFilterFactory

**参数**：无

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.TypeAsPayloadTokenFilterFactory"/>
</analyzer>
```

**输入**："Pay Bob's I.O.U."

**分词后**："Pay", "Bob's", "I.O.U."

**输出**："Pay"[<ALPHANUM>], "Bob's"[<APOSTROPHE>], "I.O.U."[<ACRONYM>]

### Type Token Filter

见原文

### Word Delimiter Filter

在给定的规则下，对词进行切分

- 词中有大小写交替："CamelCase" -> "Camel","Case"
- 字母数字混合："Gonzo5000" -> "Gonzo","50000"，"4500XL" -> "4500","XL"
- 非字母："hot-spot" -> "hot","spot"
- 移除"'s"："O'Reilly's" -> "O","Reilly"
- 删除头尾的无用分隔符："--hot-spot--" -> "hot","spot"

**工厂类**：solr.WordDelimiterFilterFactory

**参数**

- generateWordParts：（整数，默认1）如果非0，分割词："CamelCase" -> "Camel","Case"，"hot-spot" -> "hot","spot"
- generateNumberParts：（整数，默认1）如果非0，分割数字字符串："1947-32" ->"1947","32"
- splitOnCaseChange：（整数，默认1）如果0，不分割驼峰式写法："BugBlaster-XL" -> "BugBlaster", "XL"
- splitOnNumerics：（整数，默认1）如果0，不分割字符数字："FemBot3000" -> "Fem","Bot3000"
- catenateWords：（整数，默认0）如果非0，合并分割的词的结果："hot-spot-sensor's" - > "hotspotsensor"
- catenateNumbers：（整数，默认0）如果非0，合并分割后的数字的结果："1947-32" -> "194732"，否则会删除"1947-32"
- catenateAll：（整数，默认0）如果非0，合并分割后的词和数字："Zap-Master-9000" -> "ZapMaster9000"
- preserveOriginal：（整数，默认0）如果非0，提供原始词："Zap-Master-9000" -> "Zap-Master-9000", "Zap", "Master", "9000"
- protected：（选填）不进行分割的词列表的文件
- stemEnglishPossessive：（整数，默认1）如果1，从词后边去除“s”

#### 默认配置，使用WhitespaceTokenizerFactory分词器

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.WordDelimiterFilterFactory"/>
</analyzer>
```

**输入**："hot-spot RoboBlaster/9000 100XL"

**分词后**："hot-spot", "RoboBlaster/9000", "100XL"

**输出**："hot", "spot", "Robo", "Blaster", "9000", "100", "XL"

#### 不对驼峰式拼写分割，不合并数字

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.WordDelimiterFilterFactory" generateNumberParts="0" splitOnCaseChange="0"/>
</analyzer>
```

**输入**："hot-spot RoboBlaster/9000 100-42"

**分词后**："hot-spot", "RoboBlaster/9000", "100-42"

**输出**："hot", "spot", "RoboBlaster", "9000"

#### 合并词和数字，其他不处理

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.WordDelimiterFilterFactory" catenateWords="1" catenateNumbers="1"/>
</analyzer>
```

**输入**："hot-spot 100+42 XL40"

**分词后**："hot-spot"(1), "100+42"(2), "XL40"(3)

**输出**："hot"(1), "spot"(2), "hotspot"(2), "100"(3), "42"(4), "10042"(4), "XL"(5), "40"(6)

#### 合并所有

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.WordDelimiterFilterFactory" catenateAll="1"/>
</analyzer>
```

**输入**："XL-4000/ES"

**分词后**："XL-4000/ES"(1)

**输出**："XL"(1), "4000"(2), "ES"(3), "XL4000ES"(3)

#### 不处理特定词（"AstroBlaster"和"XL-5000"）

```xml
<analyzer>
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt"/>
</analyzer>
```

**输入**："FooBar AstroBlaster XL-5000 ==ES-34-"

**分词后**："FooBar", "AstroBlaster", "XL-5000", "==ES-34-"

**输出**："FooBar", "FooBar", "AstroBlaster", "XL-5000", "ES", "34"
