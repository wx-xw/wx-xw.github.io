---
layout: post
category: solr
tags: [solr,搜索]

---

## 过滤器（四）

### Remove Duplicates Token Filter

删除分词后的形同的词。

**工厂类**：solr.RemoveDuplicatesTokenFilterFactory

**参数**：无

> 在这个过滤器之前有一个同义词过滤器来造相同的词。同义词的文件synonyms.txt中数据为：
> `Television, Televisions, TV, TVs`

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"/>
  <filter class="solr.EnglishMinimalStemFilterFactory"/>
  <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
</analyzer>
```

**输入**："Watch TV"

**分词后**："Watch"(1) "TV"(2)

**同义词过滤器处理后**："Watch"(1) "Television"(2) "Televisions"(2) "TV"(2) "TVs"(2)

**词干过滤器处理后**："Watch"(1) "Television"(2) "Television"(2) "TV"(2) "TV"(2)

**输出**："Watch"(1) "Television"(2) "TV"(2)

### Reversed Wildcard Filter

反转开始为通配符，然后跟后缀的词，变味前缀+通配符模式，用于加快搜索速度。如果词没有通配符则不做处理

**工厂类**：solr.ReveresedWildcardFilterFactory

**参数**

- withOriginal：（布尔）如果真，则输出原始以及翻转后的词。如果假，则只提供翻转后的词
- maxPosAsterisk：（整形，默认为2）星号（\*）通配符会触发翻转的最高位置，高于这个位置则不触发
- maxPosQuestion：（整形，默认为1）问好（?）通配符会触发翻转的最高位置。
- maxFractionAsterisk：（浮点数，默认为0.0）如果星号（\*）通配符位置小于此百分比，则触发翻转
- minTrailing：（整形，默认为1）在通配符后的字符数，一般设为1

```xml
<analyzer type="index">
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.ReversedWildcardFilterFactory" withOriginal="true"
    maxPosAsterisk="2" maxPosQuestion="1" minTrailing="2" maxFractionAsterisk="0"/>
</analyzer>
```

**输入**："\*foo \*bar"

**分词后**："\*foo", "\*bar"

**输出**："oof\*", "rab\*"

### Shingle Filter

将单独的词合并的过滤器

**工厂类**：solr.ShingleFilterFactory

**参数**

- minShingleSize：（整形，默认为2）合并的词的最小数
- maxShingleSize：（整形，必须大于等于minShingleSize，默认为2）合并的词的最大数
- outputUnigrams：（布尔，默认为真）是否包含原始词
- outputUnigramsIfNoShingles：（布尔，默认为假）如果不能合并，是否出原始词，假则出
- tokenSeparator：（字符串，默认为" "）

#### 默认参数

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.ShingleFilterFactory"/>
</analyzer>
```

**输入**："To be, or what?"

**分词后**："To"(1), "be"(2), "or"(3), "what"(4)

**输出**："To"(1), "To be"(1), "be"(2), "be or"(2), "or"(3), "or what"(3), "what"(4)

#### 不包含原始词，并且size为4

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.ShingleFilterFactory" maxShingleSize="4" outputUnigrams="false"/>
</analyzer>
```

**输入**："To be, or not to be."

**分词后**："To"(1), "be"(2), "or"(3), "not"(4), "to"(5), "be"(6)

**输出**："To be"(1), "To be or"(1), "To be or not"(1), "be or"(2), "be or not"(2), "be or not to"(2), "or not"(3), "or not to"(3), "or not to be"(3), "not to"(4), "not to be"(4), "to be"(5)

### Snowball Porter Stemmer Filter

另一个词根提取的算法过滤器，支持多国语言

**工厂类**：solr.SnowballPorterFilterFactory

**参数**

- language：（默认英语“English”）语言名称，大小写敏感。这个字符串用于反射“org.tartarus.snowball.ext”下的class文件
- protected：用于存放保护的词，一个词一行，空行或者以#开头的行将被忽略。可以是绝对路径，也可以是solr config下的相对路径

#### 默认设置

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SnowballPorterFilterFactory"/>
</analyzer>
```

**输入**："flip flipped flipping"

**分词后**："flip", "flipped", "flipping"

**输出**："flip", "flip", "flip"

#### 法语算法，英语词

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SnowballPorterFilterFactory" language="French"/>
</analyzer>
```

**输入**："flip flipped flipping"

**分词后**："flip", "flipped", "flipping"

**输出**："flip", "flipped", "flipping"

#### 西班牙语算法，西班牙语词

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.SnowballPorterFilterFactory" language="Spanish"/>
</analyzer>
```

**输入**："cante canta"

**分词后**："cante", "canta"

**输出**："cant", "cant"

### Standard Filter

**工厂类**：solr.StandardFilterFactory

**参数**：无

> 3.1版本后已经没有此过滤器了

### Stop Filter

停用词过滤器，默认的停用词已经包含在solr config的示例中了，名称为stopwords.txt，包含了比较典型的英语停用词

**工厂类**：solr.StopFilterFactory

**参数**

- words：（选填）停用词文件路径，默认文件格式为每行一个停用词，空行或者#开头的忽略，可以绝对路径或者solr config下的相对路径
- format：（选填）文件格式，可以指定为“format="snowball"”
- ignoreCase：（布尔，默认为假）忽略大小写，如果是真，则停用词表应该全是小写词
- enablePositionIncrements：lucene 5.0以后版本，此参数无效。4.4以前版本，enablePositionIncrements="false"代表在移除的词中不用空格占位

#### 大小写敏感

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
</analyzer>
```

**输入**："To be or what?"

**分词后**："To"(1), "be"(2), "or"(3), "what"(4)

**输出**："To"(1), "what"(4)

#### 大小写不敏感

```xml
<analyzer>
  <tokenizer class="solr.StandardTokenizerFactory"/>
  <filter class="solr.StopFilterFactory" words="stopwords.txt" ignoreCase="true"/>
</analyzer>
```

**输入**："To be or what?"

**分词后**："To"(1), "be"(2), "or"(3), "what"(4)

**输出**："what"(4)

### Suggest Stop Filter

与停用词过滤器类似，但是不会删除位置在所有分词最后的停用词。建议在索引阶段使用停用词过滤器，搜索阶段使用此过滤器。

**工厂类**：solr.SuggestStopFilterFactory

**参数**

- words：（选填）停用词文件路径
- format：（选填，默认：wordset）
	- wordset：没个词一行，如果是空行或者以#开头，则忽略。
	- snowball：这种格式支持多个词一行，用“\|”分割。空行忽略
- ignoreCase：（选填，布尔，默认假）如果真，则大小写敏感

```xml
<analyzer type="query">
  <tokenizer class="solr.WhitespaceTokenizerFactory"/>
  <filter class="solr.LowerCaseFilterFactory"/>
  <filter class="solr.SuggestStopFilterFactory" ignoreCase="true" words="stopwords.txt" format="wordset"/>
</analyzer>
```

**输入**："The The"

**分词后**："the"(1), "the"(2)

**输出**："the"(2)
